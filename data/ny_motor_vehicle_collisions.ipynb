{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Motor Vehicle collisions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Source ............. https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95\n",
    "Usage tips ......... https://dev.socrata.com/foundry/data.cityofnewyork.us/h9gi-nx95\n",
    "More tips .......... https://dev.socrata.com/docs/queries/\n",
    "geospatial.......... https://scitools.org.uk/cartopy/docs/latest/getting_started/index.html\n",
    "ny geomap .......... https://geopandas.org/en/stable/gallery/plotting_basemap_background.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_api_chunk(api, limit=1000, offset=0):\n",
    "#     source = f\"{api}?${limit=}&${offset=}\"\n",
    "#     r = requests.get(source)\n",
    "#     data = pd.DataFrame.from_dict(r.json()) # read directly from json instead? faster?\n",
    "#     return data\n",
    "\n",
    "# use https://docs.python.org/3/reference/expressions.html#yield-expressions\n",
    "\n",
    "\n",
    "def read_api_chunk(api, limit=1000, offset=0):\n",
    "    \"\"\"read a single chunk from the api\"\"\"\n",
    "    return pd.read_json(f\"{api}?${limit=}&${offset=}\")\n",
    "\n",
    "\n",
    "def read_api(api, size=1000, chunk_size=1000):\n",
    "    \"\"\"read given number of lines from api, applying the chunk_size along the way\"\"\"\n",
    "    chunk_generator = (\n",
    "        # define chunks; the last chunk might be smaller than chunk_size\n",
    "        read_api_chunk(api, limit=min(chunk_size, size - x), offset=x)\n",
    "        for x in range(0, size, chunk_size)\n",
    "    )\n",
    "    # in the generator expressions, the chunks are not yet read and stored in memory\n",
    "    # the outer paranthesis are synctactilly required for generator expressions; they\n",
    "    # are not included simply in order to permit the multiline definition\n",
    "\n",
    "    # pd.concat can handle generator expressions. According to the api reference, the objs argument\n",
    "    # accepts a sequence of DataFrame objects. This indicates that any iterable that yields DataFrame\n",
    "    # objects will be accepted, which is what chunk_generator provides.\n",
    "    return pd.concat(chunk_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input parameters\n",
    "api = \"https://data.cityofnewyork.us/resource/h9gi-nx95.json\"\n",
    "n = 50e3\n",
    "# limit = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data_raw = read_api_chunk(api, limit=int(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial cleaning of data\n",
    "data = data_raw.rename(\n",
    "    columns={\n",
    "        \"vehicle_type_code1\": \"vehicle_type_code_1\",\n",
    "        \"vehicle_type_code2\": \"vehicle_type_code_2\",\n",
    "    }\n",
    ")\n",
    "data.set_index(keys=\"collision_id\", drop=False, inplace=True)\n",
    "text_cols = [col for col in data if re.search(\"(street|contributing_factor)\", col)]\n",
    "data[text_cols] = data[text_cols].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format data to cover 5 vehicles in one column\n",
    "data_wide = pd.wide_to_long(\n",
    "    data,\n",
    "    stubnames=[\"vehicle_type_code_\", \"contributing_factor_vehicle_\"],\n",
    "    i=\"collision_id\",\n",
    "    j=\"vehicle_no\",\n",
    ")\n",
    "data_wide.rename(\n",
    "    columns={\n",
    "        \"vehicle_type_code_\": \"vehicle_type_code\",\n",
    "        \"contributing_factor_vehicle_\": \"contributing_factor_vehicle\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# keep rows for vehicle no. > 1 only if relevant information pertaining to the vehicle is present; the row is redundant otherwise\n",
    "_cnd1 = (\n",
    "    data_wide[[\"vehicle_type_code\", \"contributing_factor_vehicle\"]]\n",
    "    .notnull()\n",
    "    .any(axis=1)\n",
    ")\n",
    "_cnd2 = data_wide.index.get_level_values(level=1) == 1\n",
    "_cnd = _cnd1 | _cnd2\n",
    "data_wide = data_wide.loc[_cnd, :]\n",
    "# data_wide.dtypes\n",
    "data_wide.to_csv(\"data_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contributing Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mapping for contributing factor to their code\n",
    "confac = (\n",
    "    data_wide[\"contributing_factor_vehicle\"]\n",
    "    .drop_duplicates()\n",
    "    .dropna()\n",
    "    .reset_index(drop=True)\n",
    "    .to_frame(name=\"contributing_factor\")\n",
    ")\n",
    "\n",
    "\n",
    "def get_first_chars(input):\n",
    "    \"\"\"retrieve first character of each word in a string of words\"\"\"\n",
    "    return \"\".join(item[0].upper() for item in re.findall(\"\\w+\", input))\n",
    "\n",
    "\n",
    "confac[\"cf\"] = confac[\"contributing_factor\"].apply(get_first_chars)\n",
    "\n",
    "# if not unique, add counting index\n",
    "confac[\"n\"] = confac.groupby([\"cf\"]).cumcount()\n",
    "_k = confac[\"n\"] > 0\n",
    "confac.loc[_k, \"cf\"] = confac.loc[_k, \"cf\"] + confac.loc[_k, \"n\"].astype(\"string\")\n",
    "confac.set_index(\"contributing_factor\", inplace=True)\n",
    "\n",
    "confac.to_csv(\"output/confac.csv\")\n",
    "\n",
    "confac_cols = \"cf.\" + confac[\"cf\"]\n",
    "mapping_cf = pd.Series(confac[\"cf\"]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cf.ADRR</th>\n",
       "      <th>cf.PS</th>\n",
       "      <th>cf.FTC</th>\n",
       "      <th>cf.U</th>\n",
       "      <th>cf.PTC</th>\n",
       "      <th>cf.DI</th>\n",
       "      <th>cf.POLUI</th>\n",
       "      <th>cf.TI</th>\n",
       "      <th>cf.ULC</th>\n",
       "      <th>cf.US</th>\n",
       "      <th>...</th>\n",
       "      <th>cf.OED</th>\n",
       "      <th>cf.TCDINW</th>\n",
       "      <th>cf.THD</th>\n",
       "      <th>cf.WI</th>\n",
       "      <th>cf.VV</th>\n",
       "      <th>cf.PM</th>\n",
       "      <th>cf.SDI</th>\n",
       "      <th>cf.LUH</th>\n",
       "      <th>cf.T</th>\n",
       "      <th>n_vehicles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collision_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3456194</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460534</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528065</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136992</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277087</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cf.ADRR  cf.PS  cf.FTC  cf.U  cf.PTC  cf.DI  cf.POLUI  cf.TI  \\\n",
       "collision_id                                                                 \n",
       "3456194         False  False   False  True   False  False     False  False   \n",
       "3460534         False  False   False  True   False  False     False  False   \n",
       "3528065         False  False   False  True   False  False     False  False   \n",
       "4136992         False  False   False  True   False  False      True  False   \n",
       "4277087         False  False   False  True   False  False     False  False   \n",
       "\n",
       "              cf.ULC  cf.US  ...  cf.OED  cf.TCDINW  cf.THD  cf.WI  cf.VV  \\\n",
       "collision_id                 ...                                            \n",
       "3456194        False  False  ...   False      False   False  False  False   \n",
       "3460534        False  False  ...   False      False   False  False  False   \n",
       "3528065        False  False  ...   False      False   False  False  False   \n",
       "4136992        False  False  ...   False      False   False  False  False   \n",
       "4277087        False  False  ...   False      False   False  False  False   \n",
       "\n",
       "              cf.PM  cf.SDI  cf.LUH   cf.T  n_vehicles  \n",
       "collision_id                                            \n",
       "3456194       False   False   False  False           1  \n",
       "3460534       False   False   False  False           1  \n",
       "3528065       False   False   False  False           2  \n",
       "4136992       False   False   False  False           2  \n",
       "4277087       False   False   False  False           2  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine dummies grouped by collision_id\n",
    "data_wide[\"cf\"] = data_wide[\"contributing_factor_vehicle\"].replace(mapping_cf)\n",
    "dummies_cf_long = pd.get_dummies(data_wide, columns=[\"cf\"], prefix_sep=\".\")\n",
    "dummies_cf = dummies_cf_long[confac_cols].groupby(level=0).max()\n",
    "dummies_cf[\"n_vehicles\"] = dummies_cf.sum(axis=1)\n",
    "dummies_cf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vehicle types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_codes = data_wide[\"vehicle_type_code\"].astype(\"string\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit number of vehicle categories\n",
    "# https://stackoverflow.com/questions/56440580/how-to-get-dummies-of-only-those-values-that-occur-more-than-x-time-in-pandas\n",
    "v_cats = data_wide[\"vehicle_type_code\"].value_counts().head(30)\n",
    "# data_wide[\"vehicle_type_code\"].str.replace(pat=r'\\W+', repl=\"_\", regex=True).value_counts().head(30)\n",
    "data_wide[\"vehicle_type\"] = data_wide[\"vehicle_type_code\"].str.replace(pat=r'\\W+', repl=\"_\", regex=True).str.lower()\n",
    "data_wide[\"vehicle_type\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vt\n",
       "sedan                                  41994\n",
       "station_wagon_sport_utility_vehicle    30460\n",
       "bike                                    2483\n",
       "box_truck                               1950\n",
       "pick_up_truck                           1933\n",
       "taxi                                    1796\n",
       "bus                                     1550\n",
       "e_bike                                  1110\n",
       "motorcycle                               859\n",
       "tractor_truck_diesel                     722\n",
       "van                                      590\n",
       "e_scooter                                567\n",
       "ambulance                                541\n",
       "other                                    430\n",
       "moped                                    331\n",
       "dump                                     329\n",
       "pk                                       206\n",
       "convertible                              179\n",
       "flat_bed                                 168\n",
       "garbage_or_refuse                        164\n",
       "carry_all                                145\n",
       "motorbike                                129\n",
       "motorscooter                             129\n",
       "tow_truck_wrecker                        127\n",
       "tractor_truck_gasoline                    85\n",
       "chassis_cab                               58\n",
       "4_dr_sedan                                55\n",
       "tanker                                    47\n",
       "fire_truck                                42\n",
       "3_door                                    34\n",
       "concrete_mixer                            31\n",
       "refrigerated_van                          28\n",
       "limo                                      26\n",
       "tow_truck                                 26\n",
       "unknown                                   24\n",
       "trailer                                   24\n",
       "armored_truck                             22\n",
       "scooter                                   22\n",
       "flat_rack                                 21\n",
       "firetruck                                 20\n",
       "unk                                       20\n",
       "beverage_truck                            20\n",
       "multi_wheeled_vehicle                     19\n",
       "open_body                                 18\n",
       "school_bus                                18\n",
       "stake_or_rack                             16\n",
       "lift_boom                                 14\n",
       "truck                                     11\n",
       "pedicab                                   11\n",
       "commercial                                10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce to top 50 most frequent types of cars. last category is set to \"other\"\n",
    "top = 50\n",
    "vehicle_top_cats = data_wide[\"vehicle_type\"].value_counts().head(top - 1).index\n",
    "data_wide[\"vt\"] = data_wide[\"vehicle_type\"]\n",
    "\n",
    "data_wide.loc[\n",
    "    ~data_wide[\"vehicle_type\"].isin(vehicle_top_cats)\n",
    "    & ~data_wide[\"vehicle_type\"].isna(),\n",
    "    [\"vt\"],\n",
    "] = \"other\"\n",
    "\n",
    "data_wide[\"vt\"] = data_wide[\"vt\"].astype(\"category\")\n",
    "data_wide[\"vt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_long = pd.get_dummies(data_wide, prefix=[\"vt\", \"cf\"], columns=[\"vt\", \"cf\"], prefix_sep=\".\")\n",
    "dummies = dummies_long.filter(regex=r\"^(vt|cf)\\.\").groupby(level=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "data2 = data.join(dummies)\n",
    "data2.to_csv(\"output/data2.csv\")\n",
    "X = data2.filter(regex=r\"^(vt|cf)\\.\", axis=1)\n",
    "y = data2[\"number_of_persons_injured\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ridge classifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html#sklearn.linear_model.RidgeClassifier\n",
    "clf_ridge = RidgeClassifier()\n",
    "clf_ridge.fit(X_train, y_train)\n",
    "clf_ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71464"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test random tree classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn-ensemble-randomforestclassifier\n",
    "clf_rfc = RandomForestClassifier(n_estimators=10)\n",
    "# clf_rfc = clf_rfc.fit(X_train, y_train)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "clf_rfc.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71696"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "clf_dct = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_dct.fit(X_train, y_train)\n",
    "clf_dct.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69096"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn-neighbors-kneighborsclassifier\n",
    "clf_knn = KNeighborsClassifier(algorithm='ball_tree')\n",
    "clf_knn = clf_knn.fit(X_train, y_train)\n",
    "clf_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1166: RuntimeWarning: Number of classes in training fold (12) does not match total number of classes (13). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "c:\\Users\\hauke\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71872"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "# # Prepare the list of tuples with the first-layer classifiers\n",
    "\n",
    "\n",
    "clf_ridge = RidgeClassifier()\n",
    "clf_rfc = RandomForestClassifier(n_estimators=10)\n",
    "clf_dct = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "\n",
    "classifiers = [\n",
    "\tclf_ridge,\n",
    "    clf_rfc,\n",
    "    clf_dct\n",
    "]\n",
    "\n",
    "estimators = [\n",
    "    # ('ridge', RidgeClassifier()),\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=10)),\n",
    "    ('decision_tree', DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500))\n",
    "]\n",
    "\n",
    "# Instantiate the second-layer meta estimator\n",
    "clf_meta = LogisticRegression()\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "\n",
    "# Build the stacking classifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn-ensemble-stackingclassifier\n",
    "clf_stack = StackingClassifier(\n",
    "   estimators=estimators,\n",
    "   final_estimator=clf_meta,\n",
    "   # stack_method='predict_proba',\n",
    "   passthrough = False)\n",
    "\n",
    "\n",
    "\n",
    "clf_stack.fit(X_train, y_train)\n",
    "clf_stack.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RidgeClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mclassifiers)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'RidgeClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "zip(*classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rfc.get_params()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(vehicle_type_codes)\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "def classify_cars(text):\n",
    "    if \"sedan\" in text.lower():\n",
    "        return \"Sedan\"\n",
    "    if \"truck\" in text.lower() or \"dump\" in text.lower():\n",
    "        return \"Truck\"\n",
    "    if \"sport utility vehicle\" in text.lower():\n",
    "        return \"SUV\"\n",
    "    if \"van\" in text.lower() or \"sprinter\" in text.lower():\n",
    "        return \"Van\"\n",
    "    if \"bike\" in text.lower():\n",
    "        return \"Bike\"\n",
    "    if \"taxi\" in text.lower():\n",
    "        return \"Taxi\"\n",
    "    if text in [\"Bike\", \"Motorcycle\", \"Bus\", \"E-Scooter\", \"Ambulance\"] :\n",
    "        return text\n",
    "    return \"other\"\n",
    "\n",
    "car_mapping = {\n",
    "    \"sedan\": \"Sedan\",\n",
    "    \"truck\": [\"Truck\", \"Dump\", \"Garbage or Refuse\"]\n",
    "}\n",
    "\n",
    "# data_wide[\"vehicle_type_cat\"] = data_wide[\"vehicle_type_code\"].astype(\"str\").apply(classify_cars)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols_contributing_factor = [\n",
    "    col for col in data if re.match(r\"^contributing_factor\", col)\n",
    "]\n",
    "# pd.Series(data.columns).astype(\"string\").str.startswith(\"contributing\")\n",
    "# print(cols_contributing_factor)\n",
    "# data.filter(regex=r\"^vehicle\", axis=1).isnull().sum(axis=1)\n",
    "vehicle_type_cols = data.columns.to_series().filter(regex=r\"^vehicle\").to_list()\n",
    "data[\"number_of_vehicles\"] = len(vehicle_type_cols) - data[\n",
    "    vehicle_type_cols\n",
    "].isnull().sum(axis=1)\n",
    "contributing_factor_cols = (\n",
    "    data.columns.to_series().filter(regex=r\"^contributing_factor\").to_list()\n",
    ")\n",
    "data[\"number_of_contributing_factors\"] = len(contributing_factor_cols) - data[\n",
    "    contributing_factor_cols\n",
    "].isnull().sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "on how to map categories, see here: https://stackoverflow.com/questions/62963350/how-to-categorize-a-column-with-regex-patterns\n",
    "see also here: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"on_street_name\"].str.split(\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injured Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"number_of_cyclist_injured\"].value_counts(dropna=True)\n",
    "# data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing factors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# determine contributing factors\n",
    "confac_ = pd.concat(\n",
    "    (data[col] for col in data if re.match(\"contributing_factor_vehicle\", col))\n",
    ")\n",
    "confac = confac_.drop_duplicates().dropna().to_frame(name=\"ContributingFactor\")\n",
    "\n",
    "\n",
    "# get dummies\n",
    "# filter by number of involved vehicles\n",
    "# add rolling count\n",
    "# use mapping\n",
    "# extract leading characters\n",
    "def get_first_chars(input):\n",
    "    \"\"\"retrieve first character of each word\"\"\"\n",
    "    return \"\".join(item[0].upper() for item in re.findall(\"\\w+\", input))\n",
    "\n",
    "\n",
    "confac[\"CF\"] = confac[\"ContributingFactor\"].apply(get_first_chars)\n",
    "confac[\"CFCount\"] = confac.groupby([\"CF\"]).cumcount()\n",
    "# confac.loc[confac[\"MnemoCount\"] > 0, [\"Mnemo\", \"MnemoCount\"]]\n",
    "confac.loc[confac[\"CFCount\"] > 0, \"CF\"] = confac.loc[\n",
    "    confac[\"CFCount\"] > 0, \"CF\"\n",
    "] + confac.loc[confac[\"CFCount\"] > 0, \"CFCount\"].astype(\"string\")\n",
    "confac.set_index(\"ContributingFactor\", inplace=True)\n",
    "confac_mapping = pd.Series(confac[\"CF\"]).to_dict()\n",
    "\n",
    "cf_cols = [\n",
    "    re.sub(\"contributing_factor_vehicle_\", \"CFV\", col)\n",
    "    for col in contributing_factor_cols\n",
    "]\n",
    "data[cf_cols] = data[contributing_factor_cols].replace(confac_mapping)\n",
    "# pd.get_dummies(data, columns=cf_cols)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.filter(regex=r\"^CF\", axis=1)\n",
    "# pd.get_dummies(data, columns=cf_cols).filter(regex=r\"^CF\", axis=1)\n",
    "# use pd.wide_to_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
