{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Motor Vehicle collisions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Source ............. https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95\n",
    "Usage tips ......... https://dev.socrata.com/foundry/data.cityofnewyork.us/h9gi-nx95\n",
    "More tips .......... https://dev.socrata.com/docs/queries/\n",
    "geospatial.......... https://scitools.org.uk/cartopy/docs/latest/getting_started/index.html\n",
    "ny geomap .......... https://geopandas.org/en/stable/gallery/plotting_basemap_background.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define functions to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_api_chunk(api, limit=1000, offset=0):\n",
    "#     source = f\"{api}?${limit=}&${offset=}\"\n",
    "#     r = requests.get(source)\n",
    "#     data = pd.DataFrame.from_dict(r.json()) # read directly from json instead? faster?\n",
    "#     return data\n",
    "\n",
    "# use https://docs.python.org/3/reference/expressions.html#yield-expressions\n",
    "\n",
    "def read_api_chunk(api, limit=1000, offset=0):\n",
    "    \"\"\" read a single chunk from the api\n",
    "    \"\"\"\n",
    "    return pd.read_json(f\"{api}?${limit=}&${offset=}\")\n",
    "\n",
    "def read_api(api, size=1000, chunk_size=1000):\n",
    "    \"\"\" read given number of lines from api, applying the chunk_size along the way\n",
    "    \"\"\"\n",
    "    chunk_generator = ( \n",
    "        # define chunks; the last chunk might be smaller than chunk_size\n",
    "        read_api_chunk(api, limit=min(chunk_size, size - x), offset=x) \n",
    "        for x in range(0, size, chunk_size)\n",
    "        )\n",
    "        # in the generator expressions, the chunks are not yet read and stored in memory\n",
    "        # the outer paranthesis are synctactilly required for generator expressions; they \n",
    "        # are not included simply in order to permit the multiline definition\n",
    "    \n",
    "    # pd.concat can handle generator expressions. According to the api reference, the objs argument\n",
    "    # accepts a sequence of DataFrame objects. This indicates that any iterable that yields DataFrame\n",
    "    # objects will be accepted, which is what chunk_generator provides. \n",
    "    return pd.concat(chunk_generator) \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = \"https://data.cityofnewyork.us/resource/h9gi-nx95.json\"\n",
    "size = 12000\n",
    "limit = 1000\n",
    "# data = read_api(api, size=12500)\n",
    "data_raw = read_api_chunk(api, limit=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()\n",
    "data_raw.columns\n",
    "data = data_raw\n",
    "data.rename(columns={\"vehicle_type_code1\":\"vehicle_type_code_1\", \"vehicle_type_code2\":\"vehicle_type_code_2\"}, inplace=True)\n",
    "data = pd.wide_to_long(data, stubnames=[\"vehicle_type_code_\", \"contributing_factor_vehicle_\"], i=\"collision_id\", j=\"vehicle_no\")\n",
    "data = data.loc[data[\"vehicle_type_code_\"].isnull() & data[\"contributing_factor_vehicle_\"].isnull(), :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crash_date                               object\n",
       "crash_time                       datetime64[ns]\n",
       "on_street_name                           object\n",
       "off_street_name                          object\n",
       "number_of_persons_injured                 int64\n",
       "number_of_persons_killed                  int64\n",
       "number_of_pedestrians_injured             int64\n",
       "number_of_pedestrians_killed              int64\n",
       "number_of_cyclist_injured                 int64\n",
       "number_of_cyclist_killed                  int64\n",
       "number_of_motorist_injured                int64\n",
       "number_of_motorist_killed                 int64\n",
       "contributing_factor_vehicle_1            object\n",
       "contributing_factor_vehicle_2            object\n",
       "collision_id                              int64\n",
       "vehicle_type_code1                       object\n",
       "vehicle_type_code2                       object\n",
       "borough                                  object\n",
       "zip_code                                float64\n",
       "latitude                                float64\n",
       "longitude                               float64\n",
       "location                                 object\n",
       "cross_street_name                        object\n",
       "contributing_factor_vehicle_3            object\n",
       "vehicle_type_code_3                      object\n",
       "contributing_factor_vehicle_4            object\n",
       "vehicle_type_code_4                      object\n",
       "contributing_factor_vehicle_5            object\n",
       "vehicle_type_code_5                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [col for col in data if re.search(\"(street|contributing_factor)\", col)]\n",
    "data[text_cols] = data[text_cols].astype(\"string\")\n",
    "cols_contributing_factor = [col for col in data if re.match(r\"^contributing_factor\", col)]\n",
    "# pd.Series(data.columns).astype(\"string\").str.startswith(\"contributing\")\n",
    "# print(cols_contributing_factor)\n",
    "# data.filter(regex=r\"^vehicle\", axis=1).isnull().sum(axis=1)\n",
    "vehicle_type_cols = data.columns.to_series().filter(regex=r\"^vehicle\").to_list()\n",
    "data[\"number_of_vehicles\"] = len(vehicle_type_cols) - data[vehicle_type_cols].isnull().sum(axis=1)\n",
    "contributing_factor_cols = data.columns.to_series().filter(regex=r\"^contributing_factor\").to_list()\n",
    "data[\"number_of_contributing_factors\"] = len(contributing_factor_cols) - data[contributing_factor_cols].isnull().sum(axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "on how to map categories, see here: https://stackoverflow.com/questions/62963350/how-to-categorize-a-column-with-regex-patterns\n",
    "see also here: https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [WHITESTONE, EXPRESSWAY]\n",
       "1        [QUEENSBORO, BRIDGE, UPPER]\n",
       "2             [THROGS, NECK, BRIDGE]\n",
       "3                               <NA>\n",
       "4                 [SARATOGA, AVENUE]\n",
       "                    ...             \n",
       "14995               [JEROME, AVENUE]\n",
       "14996       [NORTH, CONDUIT, AVENUE]\n",
       "14997                           <NA>\n",
       "14998                    [4, AVENUE]\n",
       "14999                   [89, STREET]\n",
       "Name: on_street_name, Length: 15000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"on_street_name\"].str.split(\" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Injured Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_cyclist_injured\n",
       "0    14331\n",
       "1      660\n",
       "2        9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"number_of_cyclist_injured\"].value_counts(dropna=True)\n",
    "# data.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine contributing factors\n",
    "confac_ = pd.concat((data[col] for col in data if re.match(\"contributing_factor_vehicle\", col)))\n",
    "confac = confac_.drop_duplicates().dropna().to_frame(name=\"ContributingFactor\")\n",
    "# get dummies\n",
    "# filter by number of involved vehicles\n",
    "# add rolling count\n",
    "# use mapping\n",
    "# extract leading characters\n",
    "def get_first_chars(input):\n",
    "    \"\"\" retrieve first character of each word\n",
    "    \"\"\"\n",
    "    return \"\".join(item[0].upper() for item in re.findall(\"\\w+\", input))\n",
    "\n",
    "confac[\"CF\"] = confac[\"ContributingFactor\"].apply(get_first_chars)\n",
    "confac[\"CFCount\"] = confac.groupby([\"CF\"]).cumcount()\n",
    "# confac.loc[confac[\"MnemoCount\"] > 0, [\"Mnemo\", \"MnemoCount\"]]\n",
    "confac.loc[confac[\"CFCount\"] > 0, \"CF\"] = \\\n",
    "    confac.loc[confac[\"CFCount\"] > 0, \"CF\"] + \\\n",
    "    confac.loc[confac[\"CFCount\"] > 0, \"CFCount\"].astype(\"string\")\n",
    "confac.set_index(\"ContributingFactor\", inplace=True)\n",
    "confac_mapping = pd.Series(confac[\"CF\"]).to_dict()\n",
    "\n",
    "cf_cols = [\n",
    "    re.sub('contributing_factor_vehicle_', 'CFV', col) \n",
    "    for col in contributing_factor_cols\n",
    "    ]\n",
    "data[cf_cols] = data[contributing_factor_cols].replace(confac_mapping)\n",
    "# pd.get_dummies(data, columns=cf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CFV1</th>\n",
       "      <th>CFV2</th>\n",
       "      <th>CFV3</th>\n",
       "      <th>CFV4</th>\n",
       "      <th>CFV5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADRR</td>\n",
       "      <td>U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTC</td>\n",
       "      <td>U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>DID</td>\n",
       "      <td>PTC</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>ULC</td>\n",
       "      <td>U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>FTYROW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>DI</td>\n",
       "      <td>DI</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>POLUI</td>\n",
       "      <td>U</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CFV1  CFV2  CFV3  CFV4  CFV5\n",
       "0        ADRR     U  <NA>  <NA>  <NA>\n",
       "1          PS  <NA>  <NA>  <NA>  <NA>\n",
       "2         FTC     U  <NA>  <NA>  <NA>\n",
       "3           U  <NA>  <NA>  <NA>  <NA>\n",
       "4        <NA>  <NA>  <NA>  <NA>  <NA>\n",
       "...       ...   ...   ...   ...   ...\n",
       "14995     DID   PTC  <NA>  <NA>  <NA>\n",
       "14996     ULC     U  <NA>  <NA>  <NA>\n",
       "14997  FTYROW  <NA>  <NA>  <NA>  <NA>\n",
       "14998      DI    DI  <NA>  <NA>  <NA>\n",
       "14999   POLUI     U  <NA>  <NA>  <NA>\n",
       "\n",
       "[15000 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(regex=r\"^CF\", axis=1)\n",
    "# pd.get_dummies(data, columns=cf_cols).filter(regex=r\"^CF\", axis=1)\n",
    "# use pd.wide_to_long\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
